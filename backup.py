from flask import Flask, render_template, request, jsonify, send_file, session
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from tqdm import tqdm
import time

import subprocess
import os
import csv
import pickle
import pandas as pd
import json
import re

app = Flask(__name__)
app.secret_key = 'salman secret key'
app.config['UPLOAD_FOLDER'] = 'pdf_upload'
app.config['OUTPUT_FOLDER'] = 'pdf_output'


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/about.html')
def about():
    return render_template('about.html')

# Fungsi ekstraksi metadata PDF


def extract_metadata(pdf_path):
    result = subprocess.check_output(
        ['python', 'pdfid/pdfid.py', pdf_path], text=True, cwd=os.getcwd())

    metadata = {
        "PDFIDVersion": "PDFiD 0.2.8",
        "FileName": os.path.basename(pdf_path),
    }

    for line in result.strip().split('\n'):
        key, value = line.strip().split(None, 1)
        if not key.startswith("PDFiD, "):
            if key == "PDF":
                key = "Header"
                value = value.split(": ")[1]
            elif value.startswith("> 2^24"):
                value = value.lstrip("> 2^24")
            elif key.startswith("/"):
                key = key[1:]

            key = {
                "obj": "Obj",
                "endobj": "Endobj",
                "stream": "Stream",
                "endstream": "Endstream",
                "xref": "Xref",
                "trailer": "Trailer",
                "startxref": "StartXref",
                "Page": "PageNo",
                "JavaScript": "Javascript",
                "AcroForm": "Acroform",
                "/Colors": "Colors",
            }.get(key, key)

            metadata[key] = int(value) if value.isnumeric() else value

    metadata.pop("PDFiD", None)

    return metadata

# Fungsi untuk menyimpan metadata ke dalam file CSV


def save_metadata_to_csv(metadata, output_path):
    with open(output_path, 'w', newline='') as output_file:
        csv_writer = csv.writer(output_file, delimiter=',')
        csv_writer.writerow(metadata.keys())
        csv_writer.writerow(metadata.values())

# Fungsi untuk menyimpan metadata ke dalam file JSON


def save_metadata_to_json(metadata, output_path):
    with open(output_path, 'w') as json_file:
        json.dump(metadata, json_file, indent=4)


@app.route('/predict', methods=['POST'])
def predict():
    if 'pdf_file' not in request.files:
        return jsonify({'error': 'No file part'})

    if not os.path.exists(app.config['UPLOAD_FOLDER']):
        os.makedirs(app.config['UPLOAD_FOLDER'])

    if not os.path.exists(app.config['OUTPUT_FOLDER']):
        os.makedirs(app.config['OUTPUT_FOLDER'])

    pdf_file = request.files['pdf_file']

    # Inisialisasi tqdm
    progress_bar = tqdm(total=100, position=0, leave=False)

    # Simulasi prediksi (gantilah dengan logika sesuai kebutuhan)
    for i in range(1, 101):
        # Simpan kemajuan prediksi dalam sesi
        session['progress'] = i

        # Perbarui tqdm
        progress_bar.update(1)

        # Tambahkan logika prediksi di sini
        time.sleep(0.1)  # Simulasi proses prediksi

    # Bersihkan kemajuan setelah selesai
    session.pop('progress', None)

    # Tutup tqdm
    progress_bar.close()

    if pdf_file.filename == '':
        return jsonify({'error': 'No selected file'})

    if pdf_file and pdf_file.filename.endswith('.pdf'):
        try:
            # Simpan file PDF yang diunggah
            pdf_path = os.path.join(
                app.config['UPLOAD_FOLDER'], pdf_file.filename)
            pdf_file.save(pdf_path)

            # Ekstrak metadata dari file PDF
            metadata = extract_metadata(pdf_path)

            # Simpan hasil ekstraksi metadata ke dalam format CSV dan JSON
            csv_output_path = os.path.join('pdf_output', 'output_metadata.csv')
            json_output_path = os.path.join(
                'pdf_output', 'output_metadata.json')

            save_metadata_to_csv(metadata, csv_output_path)
            save_metadata_to_json(metadata, json_output_path)

            os.remove(pdf_path)

            # Load Model
            model = "new_rf.pkl"
            with open(f'./model/{model}', 'rb') as model_file:
                loaded_model = pickle.load(model_file)

            print(f'Model\t\t\t: {model_file}')

            # Buat DataFrame dari metadata
            df = pd.DataFrame([metadata])

            # Hapus kolom yang tidak digunakan jika ada
            if 'URI' in df:
                df.drop(columns=['URI'], inplace=True)

            if 'PDFIDVersion' in df:
                df.drop(columns=['PDFIDVersion'], inplace=True)

            if 'FileName' in df:
                df.drop(columns=['FileName'], inplace=True)

            if 'Header' in df.columns:
                # Hapus karakter "\t" dari awal dan karakter " dari akhir
                df['Header'] = df['Header'].str.lstrip('\t').str.rstrip('"')

                # Buat kamus pemetaan
                header_mapping = {
                    "%PDF-1.0": 0,
                    "%PDF-1.1": 1,
                    "%PDF-1.2": 2,
                    "%PDF-1.3": 3,
                    "%PDF-1.4": 4,
                    "%PDF-1.5": 5,
                    "%PDF-1.6": 6,
                    "%PDF-1.7": 7
                }

                # Map 'Header' values to numerical categories
                df['Header'] = df['Header'].map(header_mapping).fillna(9999999)

                # Define a function to replace non-integer data with 9999999
                def replace_non_integer_data(value):
                    try:
                        return int(value)
                    except ValueError:
                        return 9999999

                # Columns to convert
                columns_to_convert = ['Obj', 'Endobj', 'Stream',
                                      'Endstream', 'Xref', 'Trailer', 'StartXref']

                # Apply the conversion function to selected columns
                df[columns_to_convert] = df[columns_to_convert].map(
                    replace_non_integer_data)

                # Replace unusual data values with 9999999 in string-like columns
                for column in df.columns:
                    if df[column].dtype == 'object':
                        unique_values = df[column].value_counts()
                        unusual_data = [item for item in unique_values.index if re.match(
                            r'\S+\(\S+\)|>', item)]
                        df[column] = df[column].replace(unusual_data, 9999999)

                # Misalnya, menggantikan missing values dengan mean
                imputer = SimpleImputer(strategy='mean')
                df[df.columns] = imputer.fit_transform(df)

                # Lakukan prediksi
                prediction = loaded_model.predict(df)

                # Klasifikasi prediksi sebagai "Malicious" atau "Benign"
                result = "Malicious" if 1 in prediction else "Benign"

                print(f'Prediction Result\t: {result}')

                # Persiapkan respons JSON
                response_data = {
                    'metadata': metadata,
                    'result': result
                }
                print(response_data)
                return jsonify(response_data)
            else:
                return jsonify({'error': 'Metadata does not contain "Header" column'})
        except subprocess.CalledProcessError as e:
            return jsonify({'error': f'Error extracting metadata: {str(e)}'})
    else:
        return jsonify({'error': 'Invalid file format'})


@app.route('/download-csv')
def download_csv():
    return send_file('pdf_output/output_metadata.csv', mimetype='text/csv', as_attachment=True)


@app.route('/download-json')
def download_json():
    return send_file('pdf_output/output_metadata.json', mimetype='application/json', as_attachment=True)


if __name__ == '__main__':
    app.run(host='127.0.0.1', port=5000, debug=True)
